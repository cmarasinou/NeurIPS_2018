Authors study model understanding in DNNs using the final pre-activation layer. Their aim is to understand how the prediction on a test point is affected by each training point. To this end, they "decompose" the pre-activation prediction on a test point into a linear combination of $$f_i^T f_t$$, where $$f_i$$ are the features of the previous hidden layer, $$i$$ indicates the i-th train point and $$t$$ the test point. The weights in the linear combination, $$\alpha_i$$, are called representation values and they argue that they are indicative of the influence of the i-th train point. Since, their method uses L2 regularization, they come up with an algorithm on how to treat pretrained networks. The strategy is to treat the pretrained network as a "teacher" network from where the new network (with L2 regularization) can learn.  
